{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different type of **Exploratory Data Analysis(EDA)**:\n",
    " * Univariate nongraphical\n",
    " * Multivariate nongraphical\n",
    " * Univariate graphical\n",
    " * Multivariate graphical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking data by having a glimpse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(df)\n",
    "dim(df)\n",
    "describe(df)\n",
    "\n",
    "# Unique values per column\n",
    "lapply(df, function(x) length(unique(x)))\n",
    "\n",
    "# Fast way to check NAs in each column of dataframe\n",
    "colSums(is.na(df))\n",
    "# or (as alternative)\n",
    "sapply(df, function(x)sum(is.na(x)))\n",
    "       \n",
    "#Check the percentage of Missing values       \n",
    "missing_values <- df %>% summarize_all(funs(sum(is.na(.))/n()))\n",
    "missing_values <- gather(missing_values, key=\"feature\", value=\"missing_pct\")\n",
    "       \n",
    "## Another approach for getting a full vision of dataframe status\n",
    "## is using funModeling library\n",
    "library(funModeling)\n",
    "df_status(df)\n",
    "# Retrieves the distribution in a table and a plot and shows the distribution of absolute and relative numbers\n",
    "freq(data=df, input = c('colname1','colname2',...))\n",
    "# Full numerical profiling in one function automatically excludes non-numerical variables\n",
    "profiling_num(data_world_wide)\n",
    "# Plots the distribution of every numerical variable while automatically excluding the non-numerical ones       \n",
    "plot_num(data_world_wide)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select exclusively (select all columns except mentioned)\n",
    "select(df, -one_of(colname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To count the occurrence of each value\n",
    "table(df$colname)\n",
    "\n",
    "# To get the percentage of occurence\n",
    "prop.table(table(df$colname))\n",
    "       \n",
    "# In order to get most frequent value in a column of df\n",
    "tail(names(sort(table(df$colname))), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion table for two categorical variable in dataset\n",
    "with(df, CrossTable(colname1, colname2))\n",
    "\n",
    "# In order to show relation between two contiuous variable we can do the scatterplot\n",
    "ggplot(data = df, aes(x = colname1 , y = colname2)) + geom_point()\n",
    "\n",
    "# For a combination of continuous and categorical variables we can use boxplot\n",
    "ggplot(data = df, aes(x = colname1 , y = colname2)) + geom_boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One approach for spoting outliners are the using geom_jitter\n",
    "ggplot(df, aes(colname1, colname2)) + \n",
    "    geom_jitter(alpha = 0.2 ,size = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data reduction\n",
    "If you use a large amount of data, it has bigger data size and needs more resources, moreover it may produce redundant results. In order to overcome such difficulties, we can use data reduction methods. hence, the storage efficiency will increase and at the same time we can minimize the data handling costs and will minimize the analysis time also. There are several types of data reduction:\n",
    " - **Filtering and sampling**\n",
    "     - Moving average filtering\n",
    "     - Savitzky-Golay filtering\n",
    "     - High correlation filtering\n",
    "     - Bayesian filtering\n",
    " - **Binned algorithm**\n",
    "     - Equal-width binning\n",
    "     - Equal-size binning\n",
    "     - Optima binning\n",
    "     - Multi-interval discretization binning\n",
    " - **Dimensionality reduction**\n",
    "     - Principle Component Analysis (PCA)\n",
    "     - Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful Data minging/Cleaning tools for preparing messy data for analysis in R or python:\n",
    " - [OpenRefine](https://github.com/OpenRefine/OpenRefine)\n",
    " - [DataWrangler](http://vis.stanford.edu/wrangler/)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming field names by using dplyr\n",
    "df <- df %>% rename(\n",
    "  newname1 = oldname1,\n",
    "  newname2 = oldname2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First approach: simply replace NAs with mean of the column\n",
    "df <- df %>%\n",
    "    mutate( colname = ifelse(is.na(colname), mean(df$colname, na.rm=TRUE), colname))\n",
    "\n",
    "# Use the most common value to replace NAs in the desired feature. Imagine S was the most frequent \n",
    "# value for that field within the dataframe \n",
    "df$colname <- replace(df$colname, which(is.na(df$colname)), 'S')\n",
    "\n",
    "# One sublte way to filling null values in data set would be using\n",
    "# prediction based on other explanatory variables. For example, \n",
    "# here we're looking for a countinous variable based on others.\n",
    "exp_var_filler_model <- rpart(exp_var_with_many_NA ~ a_list_of_exp_vars\n",
    "                              data=df[!is.na(df$exp_var),], \n",
    "                              method=\"anova\" #since we consider that exp_var as continous, otherwise we could use `class`)\n",
    "df$exp_var[is.na(df$exp_var)] <- predict(exp_var_filler_model, \n",
    "                                         [is.na(df$exp_var),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having a random sample dataframe from the original data by having only 3 row[for sake of example]\n",
    "df_sample <- df[sample(nrow(df), 3), ]\n",
    "\n",
    "# Using dplyr to have the same result as above\n",
    "df_sample <- sample_n(df, size = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation (Feature Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Feature engineering has been described as easily the most important factor in determining the success or failure of your predictive model. Feature engineering really boils down to the human element in machine learning. How much you understand the data, with your human intuition and creativity, can make the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- df %>%\n",
    "    mutate( new_feature = case_when(raw_feature < 13 ~ \"Lower.Range\", \n",
    "                                    raw_feature >= 13 & raw_feature < 18 ~ \"Mid.Range.1\",\n",
    "                                    raw_feature >= 18 & raw_feature < 60 ~ \"Mid.Range.2\",\n",
    "                                    raw_feature >= 60 ~ \"Upper.Range\"))\n",
    "\n",
    "# In order to combine same categorical data which has very little proportion from total we can use recode method\n",
    "libray(car)\n",
    "df$cat_var <- recode(df$cat_var, \"c('group1', 'group2',...) = 'more_general_group'\")\n",
    "# Or simply\n",
    "df3$cat_var[df$cat_var %in% c('group1','group2')] = 'more_general_group'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of survivors for the different subsets\n",
    "> aggregate(Survived ~ Child + Sex, data=train, FUN=sum)\n",
    "  Child    Sex Survived\n",
    "1     0 female      195\n",
    "2     1 female       38\n",
    "3     0   male       86\n",
    "4     1   male       23\n",
    "\n",
    "# To know the total number of people in each subset\n",
    "> aggregate(Survived ~ Child + Sex, data=train, FUN=length)\n",
    "  Child    Sex Survived\n",
    "1     0 female      259\n",
    "2     1 female       55\n",
    "3     0   male      519\n",
    "4     1   male       58\n",
    "\n",
    "# To know the proportions\n",
    "> aggregate(Survived ~ Child + Sex, data=train, \n",
    "            FUN=function(x) {sum(x)/length(x)})\n",
    "  Child    Sex  Survived\n",
    "1     0 female 0.7528958\n",
    "2     1 female 0.6909091\n",
    "3     0   male 0.1657033\n",
    "4     1   male 0.3965517"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and Relationship\n",
    "Perhaps the most standard correlation measure for numeric variables is the R statistic (or Pearson coefficient) which goes from 1 positive correlation to -1 negative correlation. A value around 0 implies no correlation.\n",
    "\n",
    "Squaring this number returns the **R-squared** statistic (aka **R2**), which goes from 0 no correlation to 1 high correlation.\n",
    "\n",
    "> R statistic is highly influenced by outliers and non-linear relationships. Highly recommended to **Plot** data as checking correlation as well as thinking about outliners before evaluating correlation.**\n",
    "\n",
    "\n",
    "**<font color=blue>NOTE:</font>** Correlation can be measure better with Information Theory concepts. One of the many algorithms to measure correlation based on this is: MINE, acronym for: Maximal Information-based nonparametric exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For evaluating correlation between two columns in dataset\n",
    "cor(df$colname1, df$colname2)\n",
    "\n",
    "## For getting the correlation table between all the columns of dataset\n",
    "cor(df)\n",
    "\n",
    "## By using funModeling package\n",
    "library(funModeling)\n",
    "correlation_table(data=df, target=\"colname\")\n",
    "\n",
    "## Using MINE algorithm\n",
    "library(minerva)\n",
    "res_mine <- df %>%\n",
    "            select_if(is.numeric) %>%\n",
    "            mine(use = 'pairwise.complete.obs')\n",
    "res_mine$MIC\n",
    "\n",
    "## MINE can also help us to profile time series regarding its non-monotonicity with MAS (maximum asymmetry score).\n",
    "# MAS ~ 0 indicates monotonic function\n",
    "# MAS ~ 1 indicates non-monotonic function (always up or down)\n",
    "res_mine$MAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Correlation on categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINE -and many other algorithms- only work with numerical data. We need to do a data preparation trick, converting every categorical variable into flag (or dummy variable).\n",
    "\n",
    "If the original categorical variable has 30 possible values, it will result in 30 new columns holding the value 0 or 1, when 1 represents the presence of that category in the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "\n",
    "# selecting just categorical column(s) which we're going to convert\n",
    "df_cat=select(df, cat_colname1, cat_colname2, ...)\n",
    "# it converts all categorical variables (factor and character for R) into numerical variables\n",
    "# skipping the original so the data is ready to use\n",
    "dmy = dummyVars(\" ~ .\", data = df_cat)\n",
    "df_cat_explode = data.frame(predict(dmy, newdata = df_cat))\n",
    "# Important: If you recieve this message `Error: Missing values present in input variable 'x'. \n",
    "# Consider using use = 'pairwise.complete.obs'.` is because data has missing values.\n",
    "# Please don't omit NA without an impact analysis first, in this case it is not important. \n",
    "df_cat_explode = na.omit(df_cat_explode)\n",
    "# compute the mic!\n",
    "mine_res = mine(df_cat_explode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The corrplot package is a graphical display of a correlation matrix, confidence interval.\n",
    "library(corrploy)\n",
    "\n",
    "## simple case 1: having simple cor function as data provider\n",
    "df %>%\n",
    "  select_if(is.numeric) %>%\n",
    "  cor(use=\"complete.obs\") %>%\n",
    "  corrplot.mixed(tl.cex=0.85)\n",
    "\n",
    "# simple case 2: plotting MIC results by using circle method\n",
    "corrplot(mine_res$MIC, method=\"circle\",\n",
    "         col=brewer.pal(n=10, name=\"PuOr\"),\n",
    "         # only display upper diagonal\n",
    "         type=\"lower\", \n",
    "         #label color, size and rotation\n",
    "         tl.col=\"red\", tl.cex = 0.9, tl.srt=90, \n",
    "         # dont print diagonal (var against itself)\n",
    "         diag=FALSE, \n",
    "         # accept a any matrix, mic in this case (not a correlation\n",
    "         #   element)\n",
    "         is.corr = F)\n",
    "\n",
    "## simple case 3: same as last case but by showing correlation values on plot\n",
    "corrplot(mine_res$MIC, method=\"color\",\n",
    "         type=\"lower\", number.cex=0.7,\n",
    "         addCoef.col = \"black\", # Add coefficient of correlation\n",
    "         tl.col=\"red\", tl.srt=90, tl.cex = 0.9,\n",
    "         diag=FALSE, is.corr = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit <- lm(outcome ~ independent1 + independent2 + ..., data = train_df)\n",
    "## Getting information about the model\n",
    "summary(fit)\n",
    "\n",
    "## If we don't have any idea about which independent variables \n",
    "# should be involved in formula, we can involve all and then using\n",
    "# step()  method to simplify the complex model to simpler one.\n",
    "messy_model <- lm(outcome ~ ., data = df)\n",
    "simplified_model <- step(messy_model)\n",
    "summary(simplified_model)\n",
    "\n",
    "## Calculating model R-squared\n",
    "sum(fit$residuals^2)\n",
    "\n",
    "## Calculating R-squared of out-of-same prediction\n",
    "pred <- predict(fit, newdata=test_df)\n",
    "SSE = sum((pred - test_df$outcome)^2)\n",
    "SST = sum((test_df$outcome - mean(train_df$outcome))^2)\n",
    "R2 = 1 - SSE/SST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning and classification\n",
    "Generally there are two kind of classifier:\n",
    " - **Binary classification**\n",
    " - **Multiclass classification**\n",
    "\n",
    "Most frequent algorithm for classification:\n",
    " - Support vector machines\n",
    " - Neural networks\n",
    " - Decision trees\n",
    " - NaÃ¯ve Bayes\n",
    " - Hidden Markov models\n",
    " \n",
    "#### NaÃ¯ve Bayes\n",
    "In this algorithm, we simply need to learn the probabilities by making the assumption that the attributes A and B **are independents**, hence the reason this model is defined as an independent feature model. NaÃ¯ve Bayes is widely used in text classification because the algorithm can be trained easily and efficiently. In NaÃ¯ve Bayes, we can calculate the probability of a condition A if B (P(A|B)), if you already know the probability of B given A (P(B|A)), as well as to A (P(A)) and B (P(B)) individually, as is shown in the previous Bayes Theorem example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rpart)\n",
    "library(rpart.plot)\n",
    "# Using rpart for list of explanatory variables for a discreate outcome\n",
    "# class method (for ones and zeros output)\n",
    "rpart(Outcome ~ exp_var1 + exp_var2 + ...,\n",
    "               data=df_train,\n",
    "               method=\"class\")\n",
    "\n",
    "# If you wanted to predict a continuous variable as outcome\n",
    "rpart(Outcome ~ exp_var1 + exp_var2 + ...,\n",
    "               data=df_train,\n",
    "               method=\"anova\")\n",
    "\n",
    "# Making prediction on test dataset\n",
    "Prediction <- predict(fit, test, type = \"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "Overfitting is technically defined as a model that performs better on a training set than another simpler model, but does worse on unseen data.\n",
    "\n",
    "Use caution with decision trees, and any other algorithm actually, or you can find yourself making rules from the noise you’ve mistaken for signal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options to optimise overfitting in decision trees\n",
    "# cp determines the complexity control and minsplit governs \n",
    "# the minimum required members for each split \n",
    "rpart(Outcome ~ exp_var1 + exp_var2 + ...,\n",
    "               data=df_train,\n",
    "               method=\"class\", \n",
    "               control=rpart.control(minsplit=2, cp=0))\n",
    "# To trim trees manually in R we can use:\n",
    "new.fit <- prp(fit,snip=TRUE)$obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "Based on problem:\n",
    "- If it's a classification problem, then we can use:\n",
    "    * Logistic Regression\n",
    "    * Naive Bayes\n",
    "    * Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "Take a large collection of individually imperfect models, and their one-off mistakes are probably not going to be made by the rest of them. If we average the results of all these models, we can sometimes find a superior model from their combination than any of the individual parts. That’s how ensemble models work, they grow a lot of different models, and let their outcomes be averaged or voted across the group.\n",
    "\n",
    "### Random Forest\n",
    "Random Forest models grow trees much deeper than the decision stumps above, in fact the default behaviour is to grow each tree out as far as possible. But since the formulas for building a single decision tree are the same every time, some source of randomness is required to make these trees different from one another. Random Forests do this in two ways.\n",
    " 1. The first trick is to use bagging, for bootstrap aggregating. Bagging takes a randomized sample of the rows in your training set, with replacement.\n",
    " 2. The second source of randomness gets past this limitation though. Instead of looking at the entire pool of available variables, Random Forests take only a subset of them, typically the square root of the number available. In our case we have 10 variables, so using a subset of three variables would be reasonable. The selection of available variables is changed for each and every node in the decision trees. \n",
    " \n",
    "R’s Random Forest algorithm has a few restrictions that we did not have with our decision trees. The big one has been the elephant in the room until now, we have to clean up the missing values in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an random forest model after data prepration process\n",
    "fit <- randomForest(as.factor(outcome) ~ exp_var1 + exp_var2 + ...,\n",
    "                    data=df_train, \n",
    "                    importance=TRUE, \n",
    "                    ntree=2000)\n",
    "\n",
    "# So let’s look at what variables were important:\n",
    " varImpPlot(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There’s two types of importance measures shown above. The accuracy one tests to see how worse the model performs without each variable, so a high decrease in accuracy would be expected for very predictive variables. The Gini one digs into the mathematics behind decision trees, but essentially measures how pure the nodes are at the end of the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction <- predict(fit, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let’s not give up yet. There’s more than one ensemble model. Let’s try a forest of conditional inference trees. They make their decisions in slightly different ways, using a statistical test rather than a purity measure, but the basic construction of each tree is fairly similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages('party')\n",
    "library(party)\n",
    "\n",
    "fit <- cforest(as.factor(outcome) ~ exp_var1 + exp_var2 + ...,\n",
    "                 data = df_train, \n",
    "                 controls=cforest_unbiased(ntree=2000, mtry=3))\n",
    "\n",
    "Prediction <- predict(fit, test, OOB=TRUE, type = \"response\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
